[community]
# Refers to the community makeup of house types.
# Remaining homes will be considered of type "base" (hvac + wh)
total_number_homes = [10, 0] # list [All homes, Non-Responsive]
homes_battery = [0, 0] # list [All homes, Non-Responsive]
homes_pv = [0, 0] # list [All homes, Non-Responsive]
homes_pv_battery = [0, 0] # list [All homes, Non-Responsive]
overwrite_existing = true # Creates new config file of all homes using home info given below.
house_p_avg = 3.0 # used to generate the setpoint

[home]
# Refers to the construction of home and home subsystems.
# Parameters to be selected randomly between _dist values.
  [home.hvac]
  r_dist = [6.8, 9.2]
  c_dist = [4.25, 5.75]
  p_cool_dist = [2, 9]
  p_heat_dist = [2.0, 13.5]
  temp_sp_dist = [18, 22]
  temp_deadband_dist = [2, 3]

  [home.wh]
  r_dist = [18.7, 25.3]
  c_dist = [4.25, 5.75]
  p_dist = [5, 8]
  sp_dist = [45.5, 48.5]
  deadband_dist = [3, 5]
  size_dist = [300, 300] # tank size (liters)

  [home.wh.waterdraws]
  # n_big_draw_dist = [4, 6]
  # n_small_draw_dist = [10, 20]
  # big_draw_size_dist = [5, 10] # in liters
  # small_draw_size_dist = [0.2, 0.5]
  n_big_draw_dist = [0, 0]
  n_small_draw_dist = [0, 0]
  big_draw_size_dist = [5, 10] # in liters
  small_draw_size_dist = [0.2, 0.5]

  [home.battery]
  max_rate = 5
  capacity = 13.5
  cap_bounds = [0.15, 0.85] # for all homes with batteries
  charge_eff = 0.95
  discharge_eff = 0.99
  cons_penalty = 0.005 # battery penalty (not used)

  [home.pv]
  area = 32
  efficiency = 0.2

  [home.hems]
  # Refers to mpc parameters -- uniform across all homes
  prediction_horizon = [4] # in hours, where 0 is just the next timestep (no MPC)
  price_uncertainty = 0.3
  sub_subhourly_steps = 1 # number of steps between each RL broadcast reward price
  # minutes_per_step = 5 # Min run time (minutes) for each on/off cycle

[simulation]
  start_datetime = "2015-01-01 00"
  end_datetime = "2015-01-08 00"
  random_seed = 12
  n_nodes = 4 # for parallelization
  load_zone = "LZ_HOUSTON"
  check_type = "all"
  run_rbo_mpc = true # runs homes with MPC (no reward price signal)
  run_rl_agg = true # runs homes with MPC responding to RL aggregator
  run_rl_simplified = false # runs linear model responding to RL aggregator
  checkpoint_interval = "daily" # hourly, daily, monthly, yearly

[rl]
    version = [2.0]

  [rl.parameters]
    # Refers to parameterization of the RL agent and impacts how it learns
    learning_rate = [0.5] # Suggested ~0.001
    discount_factor = [1.0] # Suggested <0.5
    batch_size = [32] # Suggested ~30
    exploration_rate = [0.01] # in E-greedy is epsilon, in policy gradient is sigma
    twin_q = false # will default to overwriting the old run file, use versioned runs to solve this

  [rl.utility]
    # Refers to parameters that change how the electric utility uses the RL agent
    rl_agg_action_horizon = [4] # Currently not in use
    rl_agg_forecast_horizon = 1 # Determines the number of hours the utility agent forecasts
    base_price = 0.10 # Base price for utility ($/kWh)
    action_space = [-0.05, 0.05] # Max/min price signal in cent/kWh
    action_scale = 1
    hourly_steps = 4 # Subhourly steps for the utility to send price signal
    # hours_per_step = 2 # Number of hours for which RP signal is sustained
    minutes_per_step = 120 # Number of minutes for which the RP signal is sustained

  [rl.simplified]
    response_rate = 0.3
    offset = 0.2
