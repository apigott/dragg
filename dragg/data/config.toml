[community]
# Refers to the community makeup of house types.
# Remaining homes will be considered of type "base" (hvac + wh)
total_number_homes = [10, 0] # list [All homes, Non-Responsive]
homes_battery = [0, 0] # list [All homes, Non-Responsive]
homes_pv = [0, 0] # list [All homes, Non-Responsive]
homes_pv_battery = [0, 0] # list [All homes, Non-Responsive]
overwrite_existing = true # Creates new config file of all homes using home info given below.
house_p_avg = 1.0 # used to generate the setpoint

[home]
# Refers to the construction of home and home subsystems.
# Parameters to be selected randomly between _dist values.
  [home.hvac]
  r_dist = [6.8, 9.2]
  c_dist = [4.25, 5.75]
  p_cool_dist = [2, 9]
  p_heat_dist = [2.0, 13.5]
  temp_sp_dist = [18, 22]
  temp_deadband_dist = [2, 3]

  [home.wh]
  r_dist = [18.7, 25.3]
  c_dist = [4.25, 5.75]
  p_dist = [5, 8]
  sp_dist = [45.5, 48.5]
  deadband_dist = [9, 12]
  size_dist = [200, 300] # tank size (liters)

  [home.wh.waterdraws]
  n_big_draw_dist = [5, 8]
  n_small_draw_dist = [30, 50]
  big_draw_size_dist = [5, 10] # in liters
  small_draw_size_dist = [0.2, 0.5]

  [home.battery]
  max_rate = 5
  capacity = 13.5
  cap_bounds = [0.15, 0.85] # for all homes with batteries
  charge_eff = 0.95
  discharge_eff = 0.99
  cons_penalty = 0.005 # battery penalty (not used)

  [home.pv]
  area = 32
  efficiency = 0.2

  [home.hems]
  # Refers to mpc parameters -- uniform across all homes
  prediction_horizon = [6,4] # in hours, where 0 is just the next timestep (no MPC)
  price_uncertainty = 0.3
  sub_subhourly_steps = [4] # number of steps between each RL broadcast reward price
  # minutes_per_step = 5 # Min run time (minutes) for each on/off cycle
  solver = "GLPK_MI" # options are GUROBI or GLPK_MI at the moment

[simulation]
  start_datetime = "2015-01-01 00"
  end_datetime = "2015-12-15 00"
  loop_days = true
  random_seed = 12
  n_nodes = 4 # for parallelization
  load_zone = "LZ_HOUSTON"
  check_type = "all"
  run_rbo_mpc = false # runs homes with MPC (no reward price signal)
  run_rl_agg = true # runs homes with MPC responding to RL aggregator
  run_rl_simplified = false # runs linear model responding to RL aggregator
  checkpoint_interval = "daily" # hourly, daily, monthly, yearly

[rl]
  # version = ['penalizedRP', 'shiftedRP', 'do_nothing_discounted', 'do_nothing_agent_60-15_3kW', 'ppo2_discounted_learn']
  # version = ['unknown_waterdraws', 'do_nothing-unknown_waterdraws']
  # version = ['do_nothing-unknown_waterdraws', 'normalizedXU', 'normalizedU-lowerbound_avg', 'lowerbound_avg', 'normalizedU', 'smaller_action_space-waterdraws']
  # version = ['real_with_pv', 'max_load', '6hr_10dayEp', '6hr_normalizedR', '6hr_stableR', '6hr_sac','do_nothing-6hr']
  version = ['max_load2']

  [rl.parameters]
    # Refers to parameterization of the RL agent and impacts how it learns
    learning_rate = [0.01] # Suggested ~0.001
    discount_factor = [1.0] # Suggested <0.5
    batch_size = [4,32] # Suggested ~30
    exploration_rate = [0.01] # in E-greedy is epsilon, in policy gradient is sigma
    twin_q = false # will default to overwriting the old run file, use versioned runs to solve this
    # load_from = 'outputs/2015-01-01T00_2015-01-15T00/all-homes_1-horizon_4-interval_15/rl_agg/agg_horizon_4-alpha_0.0001-epsilon_0.01-beta_1.0_batch-4_version-4.0/q-results.json'

  [rl.utility]
    # Refers to parameters that change how the electric utility uses the RL agent
    rl_agg_action_horizon = [4] # Currently not in use
    rl_agg_forecast_horizon = 1 # Determines the number of hours the utility agent forecasts
    base_price = 0.1 # Base price for utility ($/kWh)
    action_space = [-1.0, 1.0] # Max/min price signal in cent/kWh
    hourly_steps = [1] # Subhourly steps for the utility to send price signal
    # hours_per_step = 2 # Number of hours for which RP signal is sustained
    minutes_per_step = 120 # Number of minutes for which the RP signal is sustained

  [rl.simplified]
    response_rate = 0.3
    offset = 0.2

[reformat]
  versions = "all"
